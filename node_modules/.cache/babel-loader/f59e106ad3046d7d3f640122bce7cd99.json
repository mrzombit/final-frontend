{"ast":null,"code":"var TYPE = require('../tokenizer').TYPE;\nvar WHITESPACE = TYPE.WhiteSpace;\nvar COMMENT = TYPE.Comment;\nmodule.exports = function readSequence(recognizer) {\n  var children = this.createList();\n  var child = null;\n  var context = {\n    recognizer: recognizer,\n    space: null,\n    ignoreWS: false,\n    ignoreWSAfter: false\n  };\n  this.scanner.skipSC();\n  while (!this.scanner.eof) {\n    switch (this.scanner.tokenType) {\n      case COMMENT:\n        this.scanner.next();\n        continue;\n      case WHITESPACE:\n        if (context.ignoreWS) {\n          this.scanner.next();\n        } else {\n          context.space = this.WhiteSpace();\n        }\n        continue;\n    }\n    child = recognizer.getNode.call(this, context);\n    if (child === undefined) {\n      break;\n    }\n    if (context.space !== null) {\n      children.push(context.space);\n      context.space = null;\n    }\n    children.push(child);\n    if (context.ignoreWSAfter) {\n      context.ignoreWSAfter = false;\n      context.ignoreWS = true;\n    } else {\n      context.ignoreWS = false;\n    }\n  }\n  return children;\n};","map":null,"metadata":{},"sourceType":"script"}